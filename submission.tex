\documentclass[12pt]{jarticle}
\usepackage[utf8]{inputenc}
\usepackage[top=30truemm, bottom=30truemm, left=20truemm, right=20truemm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{bm}
\usepackage[dvipdfmx]{graphicx}
\usepackage[dvipdfmx]{color}
\usepackage[subrefformat=parens]{subcaption}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{tocloft}
\usepackage{enumerate}
\usepackage{url}
\usepackage{multirow}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{array}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{physics}
\usepackage{hyperref}

\numberwithin{equation}{section}    % 数式番号にセクション番号をつける
\numberwithin{figure}{section}      % 図番号にセクション
\numberwithin{table}{section}      % 図番号にセクション

% \renewcommand{\figurename}{Fig.}    % 図 -> Fig.
% \renewcommand{\tablename}{Table }   % 表 -> Table

\renewcommand{\baselinestretch}{1.1}

\newlength{\figcaptionskip}
\setlength{\figcaptionskip}{5pt} % 図のキャプション間隔
\newlength{\tabcaptionskip}
\setlength{\tabcaptionskip}{-5pt} % 表のキャプション間隔
\captionsetup[figure]{skip=\figcaptionskip}
\captionsetup[table]{skip=\tabcaptionskip}

\setlist[enumerate]{topsep=5pt, partopsep=5pt, itemsep=0pt, parsep=0pt}
\setlength{\topsep}{5pt}
\setlength{\partopsep}{5pt}

\DeclareSIUnit{\fps}{fps}
\DeclareSIUnit{\dBFS}{dBFS}

\captionsetup[subfigure]{labelformat=simple}
\renewcommand{\thesubfigure}{(\alph{subfigure})}

\input{vars.tex}

\allowdisplaybreaks[4]

\begin{document}

\begin{titlepage}
    \begin{center}
        {\Large 2024年度後期　修士論文}
        \vspace{120truept}

        {\huge 深層学習による口唇動画を用いた音声合成に関する研究}
        \vspace{30truept}

        {\huge A Study on Speech Synthesis from Lip Video Using Deep Learning}
        \vspace{120truept}

        {\Large 2025年1月15日}
        \vspace{10truept}

        {\Large 九州大学芸術工学府音響設計コース}
        \vspace{70truept}

        {\Large 2DS23095M}
        \vspace{10truept}

        {\Large 南 汰翼}
        \vspace{10truept}

        {\Large MINAMI Taisuke}
        \vspace{30truept}

        {\Large 研究指導教員　鏑木 時彦　教授}
    \end{center}
\end{titlepage}

\section*{概要}
\thispagestyle{empty}
癌などの病気で喉頭を摘出した場合，元通りに発声することが不可能になる．これに対し，現状でもいくつかの代用音声が存在するが，これらにもそれぞれデメリットがある．そこで本研究では，新たな代用音声として，ビデオカメラで撮影された口唇動画を入力として音声を合成する，深層学習モデルを利用したアプローチを検討する．動画音声合成の分野では，これまでにも多くの研究によって改善が重ねられてきた．近年では，複数の予測対象を用いたマルチタスク学習や，自己教師あり学習モデルの転移学習の有効性が確認されている．しかし，動画音声合成モデルによって得られる合成音声の品質は依然として低く，自然音声に迫る合成音の実現に至っていない点が課題である．これに対し，本研究では，近年高い精度を達成した「AVHuBERTを利用したメルスペクトログラムとHuBERT離散特徴量を予測対象とするマルチタスク学習手法」をベースラインとして採用し，この手法を上回る新たなモデルを提案することで，自然音声に迫る合成音声の実現に近づくことを目的とした．ここで，動画音声合成を困難にしている一因として，同じような口唇の動きでも，場合によって異なる音素となる場合があることが挙げられる．これに対し，提案手法は自己教師あり学習モデルであるHuBERTを導入し，動画から予測された不完全な予測結果を，大量の音声データを元に学習された文脈を考慮する能力によって補完することで，最終予測値に対する予測精度改善を狙った．実験では，合成音声の明瞭性および，合成音声と原音声の類似性を，客観評価と主観評価の両面から評価した．その結果，提案手法におけるHuBERT Transformerの転移学習は仮説に反して有効ではなかったものの，HuBERT Transformerをランダム初期化した場合が有効性を示し，客観評価と主観評価の両面においてベースラインを上回った．また，本実験を通して明らかとなった課題から，さらなる改善の可能性があることも示唆された．
\clearpage

\setcounter{tocdepth}{2}
\tableofcontents
\thispagestyle{empty}
\clearpage

\pagestyle{plain}
\setcounter{page}{1}

\input{section1.tex}
\clearpage

\input{section2.tex}
\clearpage

\section{深層学習}
深層学習とは，人間の神経細胞の仕組みを模擬したニューラルネットワークを用いる機械学習手法のことである．特に近年ではその層を深くしたディープニューラルネットワーク（Deep Neural Network; DNN）が用いられ，大量のパラメータによる表現力により，自然言語処理や画像処理，音声処理など様々な分野で成果をあげている．本章では，DNNの構成要素及び，構築したDNNの学習方法について説明する．
\input{section3_1.tex}
\input{section3_2.tex}

\clearpage

\section{動画音声合成モデルの検討}
\input{section4_1.tex}
\input{section4_2.tex}
\input{section4_3.tex}
\input{section4_4.tex}

\clearpage

\section{結論}
本研究では、癌などで喉頭を摘出することによって発声が不可能となった場合における新たな代用音声として、口唇動画を入力として音声を合成する，深層学習モデルを利用したアプローチを検討した。実験では，「AVHuBERTを利用したメルスペクトログラムとHuBERT離散特徴量を予測対象とするマルチタスク学習手法」をベースラインとして採用し，この手法を上回る新たなモデルを提案することで，自然音声に迫る合成音声の実現に近づくことを目的とした．提案手法は，ネットワークA，ネットワークB，ボコーダの3つから構成されるモデルとした．ネットワークAは，AVHuBERTを中心とした構成で，動画を入力としてHuBERT中間特徴量を予測する役割を担う．ネットワークBは，HuBERT Transformerを中心とした構成で，HuBERT中間特徴量を入力としてメルスペクトログラムとHuBERT離散特徴量を予測する役割を担う．ボコーダは，先行研究に基づいたHiFi-GANベースの構成で，メルスペクトログラムとHuBERT離散特徴量を入力として音声波形に変換する役割を担う．実験では，合成音声の明瞭性および，合成音声と原音声の類似性を，客観評価と主観評価の両面から評価した．

初めに客観評価によってネットワークの比較を実施し，特に提案手法におけるより良い構成を模索した．その結果，以下の4つのことがわかった．
\begin{enumerate}
    \item ネットワークBにおけるHuBERT Transformerの単純な転移学習は有効でない．
    \item ネットワークBの入力には，HuBERT中間特徴量を用いる方が，メルスペクトログラムとHuBERT離散特徴量に対するロジットを組み合わせた特徴量を用いるよりもネットワークBの予測精度が向上する．
    \item HuBERT中間特徴量を予測するネットワークAは，メルスペクトログラムとHuBERT離散特徴量を同時に予測するマルチタスク学習を行わず，HuBERT中間特徴量のみを予測するよう学習した方がネットワークBの予測精度が向上する．
    \item ネットワークAとネットワークBの学習方法について，HuBERT中間特徴量を継ぎ目として2段階で学習する場合に対し，ネットワーク全体を1度に最適化しても予測精度は改善されない．
\end{enumerate}
次に，客観評価をもとに選択した提案手法の代表と，ベースラインとを主観評価によって比較した．その結果，以下の2つの結果が得られた．
\begin{enumerate}
    \item ベースラインに対し，提案手法が明瞭性と類似性の両面において有意に高い評価を得た．
    \item ネットワークAにおいてマルチタスク学習を行った場合，マルチタスク学習を行わない場合と比較して、類似性の評価が有意に低くなった．
\end{enumerate}

以上より，提案手法は客観評価と主観評価の両面においてベースラインを上回ったと考えられる．一方，主観評価の結果より，最も良好な結果を示した動画音声合成モデルによる合成音声でも、いまだ分析合成や原音声との差は大きいことがわかった．これより，自然音声に迫る合成音声を実現するためには，さらなる改善が必要であることが明らかとなった．

今後の課題は2つ挙げられる．1つ目は，損失関数の重み係数に対するグリッドサーチからの脱却である．客観評価の結果より，本研究で検討したモデルの多くは，重み係数の値に性能が大きく左右されることがわかった．これに対し，GradNormやDynamic Weight Averagingのように，重み係数を動的に調節し，グリッドサーチよりも柔軟なチューニングを可能にすることで，モデルのさらなる精度改善および，実験時間の短縮が期待できる．2つ目は，HuBERTの転移学習方法である．本研究では，ネットワークBにおいてHuBERT Transformerの転移学習が有効でなかったため，その後はHuBERT Transformerをランダム初期化する場合のみに検討対象を絞った．しかし，適切な損失関数の重み係数がグリッドサーチの探索範囲内に含まれていなかったことや，事前学習時とfine-tuning時の入力特徴量にギャップがあったことが課題として挙げられ，その対処によってHuBERT Transformerをランダム初期化する場合を上回る可能性もある．損失関数の重み係数については、前述した動的な調整が考えられる。学習方法については例えば，学習初期にあえて原音声から得られる特徴量を混入させて事前学習時の条件に近づけ，徐々に混入率を下げてネットワークAによる予測結果のみを入力とするようスケジューリングする方法が考えられる．

\clearpage

\section*{謝辞}
\addcontentsline{toc}{section}{謝辞}
本研究に取り組む上で熱心に指導してくださり，計算環境の整備やクラウドワークスの活用など，新しい取り組みにも前向きにご協力くださった鏑木先生に心より感謝申し上げます．

また，日頃から多くの相談に乗ってくださり，研究に対する助言をいただいた藤田さんをはじめ，ゼミや中間発表において貴重なご意見をくださった河原先生，吉永先生，そして研究室の皆様にも厚く御礼申し上げます．

\clearpage

\bibliographystyle{junsrt}
% \bibliographystyle{abbrv,unsrt}
\addcontentsline{toc}{section}{参考文献}
\bibliography{library}

\end{document}