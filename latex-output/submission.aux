\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\HyPL@Entry{1<</S/D>>}
\citation{shen2018natural}
\citation{prajwal2020learning}
\citation{kim2021lip}
\citation{vaswani2017attention}
\citation{gulati2020conformer}
\citation{mira2022svts}
\citation{kim2023lip_multitask}
\citation{choi2023intelligible}
\citation{kim2023lip_multitask}
\citation{hsu2021hubert}
\citation{choi2023intelligible}
\citation{shi2022learning}
\citation{afouras2018lrs3}
\citation{chung2018voxceleb2}
\HyPL@Entry{4<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}序論}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}背景}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}目的}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}本論文の構成}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}音声信号処理}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}音声のフーリエ変換}{3}{subsection.2.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{sec2:fig:spectrogram1}{{2.1a}{4}{窓長12.5ms，シフト幅5ms\relax }{figure.caption.2}{}}
\newlabel{sub@sec2:fig:spectrogram1}{{a}{4}{窓長12.5ms，シフト幅5ms\relax }{figure.caption.2}{}}
\newlabel{sec2:fig:spectrogram2}{{2.1b}{4}{窓長25ms，シフト幅10ms\relax }{figure.caption.2}{}}
\newlabel{sub@sec2:fig:spectrogram2}{{b}{4}{窓長25ms，シフト幅10ms\relax }{figure.caption.2}{}}
\newlabel{sec2:fig:spectrogram3}{{2.1c}{4}{窓長50ms，シフト幅20ms\relax }{figure.caption.2}{}}
\newlabel{sub@sec2:fig:spectrogram3}{{c}{4}{窓長50ms，シフト幅20ms\relax }{figure.caption.2}{}}
\newlabel{sec2:fig:spectrogram4}{{2.1d}{4}{窓長100ms，シフト幅40ms\relax }{figure.caption.2}{}}
\newlabel{sub@sec2:fig:spectrogram4}{{d}{4}{窓長100ms，シフト幅40ms\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 「小さな鰻屋に，熱気のようなものがみなぎる」と発話した音声から計算された対数パワースペクトログラム\relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{sec2:fig:log_power_spectrograms}{{2.1}{4}{「小さな鰻屋に，熱気のようなものがみなぎる」と発話した音声から計算された対数パワースペクトログラム\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}メルスペクトログラム}{5}{subsection.2.2}\protected@file@percent }
\newlabel{sec2:fig:melfb_20}{{2.2a}{6}{フィルタ数を20とした場合\relax }{figure.caption.3}{}}
\newlabel{sub@sec2:fig:melfb_20}{{a}{6}{フィルタ数を20とした場合\relax }{figure.caption.3}{}}
\newlabel{sec2:fig:melfb_80}{{2.2b}{6}{フィルタ数を80とした場合\relax }{figure.caption.3}{}}
\newlabel{sub@sec2:fig:melfb_80}{{b}{6}{フィルタ数を80とした場合\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces サンプリング周波数を16 kHzとした場合におけるメルフィルタバンク\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{sec2:fig:melfb}{{2.2}{6}{サンプリング周波数を16 kHzとした場合におけるメルフィルタバンク\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces 「小さな鰻屋に，熱気のようなものがみなぎる」と発話した音声に対する対数メルスペクトログラム\relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{sec2:fig:melspectrogram}{{2.3}{6}{「小さな鰻屋に，熱気のようなものがみなぎる」と発話した音声に対する対数メルスペクトログラム\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}深層学習}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}DNNの構成要素}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}全結合層}{7}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}畳み込み層}{7}{subsubsection.3.1.2}\protected@file@percent }
\newlabel{sec3:fig:conv1}{{3.1a}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 1, 1}$\relax }{figure.caption.5}{}}
\newlabel{sub@sec3:fig:conv1}{{a}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 1, 1}$\relax }{figure.caption.5}{}}
\newlabel{sec3:fig:conv2}{{3.1b}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {5, 1, 1}$\relax }{figure.caption.5}{}}
\newlabel{sub@sec3:fig:conv2}{{b}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {5, 1, 1}$\relax }{figure.caption.5}{}}
\newlabel{sec3:fig:conv3}{{3.1c}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 2, 1}$\relax }{figure.caption.5}{}}
\newlabel{sub@sec3:fig:conv3}{{c}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 2, 1}$\relax }{figure.caption.5}{}}
\newlabel{sec3:fig:conv4}{{3.1d}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 1, 2}$\relax }{figure.caption.5}{}}
\newlabel{sub@sec3:fig:conv4}{{d}{8}{$\lr {\kernelSizeUpper , \strideUpper , \dilationUpper } = \lr {3, 1, 2}$\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces ある次元における一次元畳み込み層の処理．$K$はカーネルサイズ，$S$はストライド，$R$はダイレーションを表し，図中の0はパディング部を表す．\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{sec3:fig:conv_variations}{{3.1}{8}{ある次元における一次元畳み込み層の処理．$\kernelSizeUpper $はカーネルサイズ，$\strideUpper $はストライド，$\dilationUpper $はダイレーションを表し，図中の0はパディング部を表す．\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}転置畳み込み層}{8}{subsubsection.3.1.3}\protected@file@percent }
\newlabel{sec3:fig:tconv1}{{3.2a}{9}{$\lr {\kernelSizeUpper , \strideUpper } = \lr {4, 1}$\relax }{figure.caption.6}{}}
\newlabel{sub@sec3:fig:tconv1}{{a}{9}{$\lr {\kernelSizeUpper , \strideUpper } = \lr {4, 1}$\relax }{figure.caption.6}{}}
\newlabel{sec3:fig:tconv2}{{3.2b}{9}{$\lr {\kernelSizeUpper , \strideUpper } = \lr {4, 2}$\relax }{figure.caption.6}{}}
\newlabel{sub@sec3:fig:tconv2}{{b}{9}{$\lr {\kernelSizeUpper , \strideUpper } = \lr {4, 2}$\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces ある次元における一次元転置畳み込み層の処理．$K$はカーネルサイズ，$S$はストライドを表す．\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{sec3:fig:tconv_variations}{{3.2}{9}{ある次元における一次元転置畳み込み層の処理．$\kernelSizeUpper $はカーネルサイズ，$\strideUpper $はストライドを表す．\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}活性化関数}{9}{subsubsection.3.1.4}\protected@file@percent }
\citation{maas2013rectifier}
\citation{he2015delving}
\citation{hendrycks2016gaussian}
\citation{hochreiter1997long}
\citation{cho2014learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}再帰型ニューラルネットワーク}{11}{subsubsection.3.1.5}\protected@file@percent }
\citation{ioffe2015batch}
\newlabel{sec3:fig:activations}{{3.3a}{12}{活性化関数\relax }{figure.caption.7}{}}
\newlabel{sub@sec3:fig:activations}{{a}{12}{活性化関数\relax }{figure.caption.7}{}}
\newlabel{sec3:fig:activations_prime}{{3.3b}{12}{活性化関数の一階導関数\relax }{figure.caption.7}{}}
\newlabel{sub@sec3:fig:activations_prime}{{b}{12}{活性化関数の一階導関数\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces 活性化関数の例\relax }}{12}{figure.caption.7}\protected@file@percent }
\newlabel{sec3:fig:activations_and_their_prime}{{3.3}{12}{活性化関数の例\relax }{figure.caption.7}{}}
\citation{ba2016layer}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.6}正規化層}{13}{subsubsection.3.1.6}\protected@file@percent }
\citation{salimans2016weight}
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.7}Transformer}{14}{subsubsection.3.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Transformer層の構造\relax }}{15}{figure.caption.8}\protected@file@percent }
\newlabel{sec3:fig:transformer_layer}{{3.4}{15}{Transformer層の構造\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}学習方法}{16}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}損失関数}{16}{subsubsection.3.2.1}\protected@file@percent }
\citation{zhang2019gradient}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}勾配降下法}{17}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{sec3:sec:gradient_descent}{{3.2.2}{17}{勾配降下法}{subsubsection.3.2.2}{}}
\newlabel{sec3:eq:normal_gradient_descent}{{3.52}{17}{勾配降下法}{equation.3.52}{}}
\citation{srivastava2014dropout}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}正則化}{18}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{sec3:eq:l2_reg}{{3.56}{18}{正則化}{equation.3.56}{}}
\newlabel{sec3:eq:weight_decay}{{3.57}{18}{正則化}{equation.3.57}{}}
\newlabel{sec3:eq:regularization_dropout_training_output}{{3.58}{18}{正則化}{equation.3.58}{}}
\citation{kingma2014adam}
\citation{loshchilov2017decoupled}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}最適化手法}{19}{subsubsection.3.2.4}\protected@file@percent }
\newlabel{sec3:sec:optimizer}{{3.2.4}{19}{最適化手法}{subsubsection.3.2.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Adam\relax }}{20}{algorithm.1}\protected@file@percent }
\newlabel{sec3:algo:adam}{{1}{20}{Adam\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces AdamW\relax }}{20}{algorithm.2}\protected@file@percent }
\newlabel{sec3:algo:adamw}{{2}{20}{AdamW\relax }{algorithm.2}{}}
\citation{higham2019deep}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}学習率のスケジューリング}{21}{subsubsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.6}誤差逆伝播法}{21}{subsubsection.3.2.6}\protected@file@percent }
\newlabel{sec3:sec:backpropagation}{{3.2.6}{21}{誤差逆伝播法}{subsubsection.3.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces スケジューラによる学習率の変化\relax }}{22}{figure.caption.9}\protected@file@percent }
\newlabel{sec3:fig:lr_scheduler}{{3.5}{22}{スケジューラによる学習率の変化\relax }{figure.caption.9}{}}
\newlabel{sec3:eq:output_before_act}{{3.67}{22}{誤差逆伝播法}{equation.3.67}{}}
\newlabel{sec3:eq:output_before_act_2}{{3.69}{22}{誤差逆伝播法}{equation.3.69}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.7}学習の安定化}{24}{subsubsection.3.2.7}\protected@file@percent }
\citation{wan2018generalized}
\@writefile{toc}{\contentsline {section}{\numberline {4}動画音声合成モデルの検討}{25}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}音声合成法}{25}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}全体像}{25}{subsubsection.4.1.1}\protected@file@percent }
\newlabel{sec4:eq:networkA_overview}{{4.4}{26}{全体像}{equation.4.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}ネットワークA}{26}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces 提案手法の全体像\relax }}{27}{figure.caption.10}\protected@file@percent }
\newlabel{sec4:fig:overview}{{4.1}{27}{提案手法の全体像\relax }{figure.caption.10}{}}
\citation{kim2023lip_multitask}
\citation{choi2023intelligible}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}ネットワークB}{28}{subsubsection.4.1.3}\protected@file@percent }
\citation{choi2023intelligible}
\newlabel{sec4:fig:networkA}{{4.2a}{29}{ネットワークA\relax }{figure.caption.11}{}}
\newlabel{sub@sec4:fig:networkA}{{a}{29}{ネットワークA\relax }{figure.caption.11}{}}
\newlabel{sec4:fig:networkB}{{4.2b}{29}{ネットワークB\relax }{figure.caption.11}{}}
\newlabel{sub@sec4:fig:networkB}{{b}{29}{ネットワークB\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces ネットワークAとネットワークBの構造\relax }}{29}{figure.caption.11}\protected@file@percent }
\newlabel{sec4:fig:networkAB}{{4.2}{29}{ネットワークAとネットワークBの構造\relax }{figure.caption.11}{}}
\citation{kong2020hifi}
\newlabel{sec4:fig:post}{{4.3a}{30}{全体\relax }{figure.caption.12}{}}
\newlabel{sub@sec4:fig:post}{{a}{30}{全体\relax }{figure.caption.12}{}}
\newlabel{sec4:fig:post_resblock}{{4.3b}{30}{$\text {ResBlock}$\relax }{figure.caption.12}{}}
\newlabel{sub@sec4:fig:post_resblock}{{b}{30}{$\text {ResBlock}$\relax }{figure.caption.12}{}}
\newlabel{sec4:fig:post_convblock}{{4.3c}{30}{$\text {ConvBlock}$\relax }{figure.caption.12}{}}
\newlabel{sub@sec4:fig:post_convblock}{{c}{30}{$\text {ConvBlock}$\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces 後処理層$f_{\text  {post}}$の構造\relax }}{30}{figure.caption.12}\protected@file@percent }
\newlabel{sec4:fig:post_three_step}{{4.3}{30}{後処理層$\myNetworkPost $の構造\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}ボコーダ}{30}{subsubsection.4.1.4}\protected@file@percent }
\newlabel{sec4:fig:vocoder_overview}{{4.4a}{31}{全体\relax }{figure.caption.13}{}}
\newlabel{sub@sec4:fig:vocoder_overview}{{a}{31}{全体\relax }{figure.caption.13}{}}
\newlabel{sec4:fig:vocoder_main}{{4.4b}{31}{$\vocoderMain $\relax }{figure.caption.13}{}}
\newlabel{sub@sec4:fig:vocoder_main}{{b}{31}{$\vocoderMain $\relax }{figure.caption.13}{}}
\newlabel{sec4:fig:vocoder_main_block}{{4.4c}{31}{$\text {UpsamplingBlock}$\relax }{figure.caption.13}{}}
\newlabel{sub@sec4:fig:vocoder_main_block}{{c}{31}{$\text {UpsamplingBlock}$\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces ボコーダの構造\relax }}{31}{figure.caption.13}\protected@file@percent }
\newlabel{sec4:fig:vocoder}{{4.4}{31}{ボコーダの構造\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.5}損失関数}{31}{subsubsection.4.1.5}\protected@file@percent }
\citation{taguchi}
\citation{esaki}
\citation{atr}
\citation{okamoto2023hi}
\citation{takamichi2019jvs}
\citation{bulat2017far}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces 利用したデータセットの文章数\relax }}{32}{table.caption.14}\protected@file@percent }
\newlabel{sec4:tab:dataset_info}{{4.1}{32}{利用したデータセットの文章数\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}実験方法}{32}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}利用したデータセット}{32}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}データの前処理}{32}{subsubsection.4.2.2}\protected@file@percent }
\citation{pasad2023comparative}
\citation{nagrani2020voxceleb}
\citation{panayotov2015librispeech}
\citation{jia2018transfer}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}本実験で利用した事前学習済みモデルについて}{33}{subsubsection.4.2.3}\protected@file@percent }
\citation{shi2022robust}
\citation{snyder2015musan}
\citation{afouras2018deep}
\citation{yin2023reazonspeech}
\citation{sawada2024release}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}本実験で独自に構築したモデルについて}{34}{subsubsection.4.2.4}\protected@file@percent }
\citation{loshchilov2017decoupled}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces $f_{\text  {voc-main}}$の各UpsamplingBlockにおけるパラメータ\relax }}{35}{table.caption.15}\protected@file@percent }
\newlabel{sec4:tab:vocoder_main_params}{{4.2}{35}{$\vocoderMain $の各UpsamplingBlockにおけるパラメータ\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}学習方法}{35}{subsubsection.4.2.5}\protected@file@percent }
\citation{radford2023robust}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6}客観評価}{36}{subsubsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7}主観評価}{37}{subsubsection.4.2.7}\protected@file@percent }
\newlabel{sec4:sec:sbj_explanation}{{4.2.7}{37}{主観評価}{subsubsection.4.2.7}{}}
\citation{kirkland2023stuck}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces 被験者に対する評価サンプル割り当て方法（明瞭性）\relax }}{39}{algorithm.3}\protected@file@percent }
\newlabel{sec4:algo:sample-assignment-int}{{3}{39}{被験者に対する評価サンプル割り当て方法（明瞭性）\relax }{algorithm.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces 被験者に対する評価サンプル割り当て方法（類似性）\relax }}{40}{algorithm.4}\protected@file@percent }
\newlabel{sec4:algo:sample-assignment-sim}{{4}{40}{被験者に対する評価サンプル割り当て方法（類似性）\relax }{algorithm.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}結果}{40}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}客観評価1: ベースラインと提案手法の比較}{40}{subsubsection.4.3.1}\protected@file@percent }
\newlabel{sec4:sec:obj_1}{{4.3.1}{40}{客観評価1: ベースラインと提案手法の比較}{subsubsection.4.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces 損失関数の重み係数$\lambda _{\text  {HuB-disc}}$による客観評価指標の変化\relax }}{43}{table.caption.16}\protected@file@percent }
\newlabel{sec4:tab:obj_weights}{{4.3}{43}{損失関数の重み係数$\lossWeightHubDisc $による客観評価指標の変化\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces 最適な$\lambda _{\text  {HuB-disc}}$における手法ごとの比較\relax }}{43}{table.caption.21}\protected@file@percent }
\newlabel{sec4:tab:obj_method_comp}{{4.4}{43}{最適な$\lossWeightHubDisc $における手法ごとの比較\relax }{table.caption.21}{}}
\newlabel{sec4:fig:learning_curve_baseline_val_mel_loss}{{4.5a}{44}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.17}{}}
\newlabel{sub@sec4:fig:learning_curve_baseline_val_mel_loss}{{a}{44}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.17}{}}
\newlabel{sec4:fig:learning_curve_baseline_val_ssl_feature_cluster_loss}{{4.5b}{44}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.17}{}}
\newlabel{sub@sec4:fig:learning_curve_baseline_val_ssl_feature_cluster_loss}{{b}{44}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.17}{}}
\newlabel{sec4:fig:learning_curve_baseline_val_total_loss}{{4.5c}{44}{損失の合計値\relax }{figure.caption.17}{}}
\newlabel{sub@sec4:fig:learning_curve_baseline_val_total_loss}{{c}{44}{損失の合計値\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces ベースラインにおける学習曲線\relax }}{44}{figure.caption.17}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_baseline_val_losses}{{4.5}{44}{ベースラインにおける学習曲線\relax }{figure.caption.17}{}}
\newlabel{sec4:fig:learning_curve_method_1_val_ssl_conv_feature_loss}{{4.6a}{45}{HuBERT中間特徴量についてのMAE Loss\relax }{figure.caption.18}{}}
\newlabel{sub@sec4:fig:learning_curve_method_1_val_ssl_conv_feature_loss}{{a}{45}{HuBERT中間特徴量についてのMAE Loss\relax }{figure.caption.18}{}}
\newlabel{sec4:fig:learning_curve_method_1_val_mel_loss}{{4.6b}{45}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.18}{}}
\newlabel{sub@sec4:fig:learning_curve_method_1_val_mel_loss}{{b}{45}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.18}{}}
\newlabel{sec4:fig:learning_curve_method_1_val_ssl_feature_cluster_loss}{{4.6c}{45}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.18}{}}
\newlabel{sub@sec4:fig:learning_curve_method_1_val_ssl_feature_cluster_loss}{{c}{45}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.18}{}}
\newlabel{sec4:fig:learning_curve_method_1_val_total_loss}{{4.6d}{45}{損失の合計値\relax }{figure.caption.18}{}}
\newlabel{sub@sec4:fig:learning_curve_method_1_val_total_loss}{{d}{45}{損失の合計値\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces ネットワークAにおける学習曲線\relax }}{45}{figure.caption.18}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_1_val_losses}{{4.6}{45}{ネットワークAにおける学習曲線\relax }{figure.caption.18}{}}
\newlabel{sec4:fig:learning_curve_method_2_val_mel_loss}{{4.7a}{46}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.19}{}}
\newlabel{sub@sec4:fig:learning_curve_method_2_val_mel_loss}{{a}{46}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.19}{}}
\newlabel{sec4:fig:learning_curve_method_2_val_ssl_feature_cluster_loss}{{4.7b}{46}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.19}{}}
\newlabel{sub@sec4:fig:learning_curve_method_2_val_ssl_feature_cluster_loss}{{b}{46}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.19}{}}
\newlabel{sec4:fig:learning_curve_method_2_val_total_loss}{{4.7c}{46}{損失の合計値\relax }{figure.caption.19}{}}
\newlabel{sub@sec4:fig:learning_curve_method_2_val_total_loss}{{c}{46}{損失の合計値\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces ネットワークB（Randomized）における学習曲線\relax }}{46}{figure.caption.19}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_2_val_losses}{{4.7}{46}{ネットワークB（Randomized）における学習曲線\relax }{figure.caption.19}{}}
\newlabel{sec4:fig:learning_curve_method_4_val_mel_loss}{{4.8a}{47}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.20}{}}
\newlabel{sub@sec4:fig:learning_curve_method_4_val_mel_loss}{{a}{47}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.20}{}}
\newlabel{sec4:fig:learning_curve_method_4_val_ssl_feature_cluster_loss}{{4.8b}{47}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.20}{}}
\newlabel{sub@sec4:fig:learning_curve_method_4_val_ssl_feature_cluster_loss}{{b}{47}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.20}{}}
\newlabel{sec4:fig:learning_curve_method_4_val_total_loss}{{4.8c}{47}{損失の合計値\relax }{figure.caption.20}{}}
\newlabel{sub@sec4:fig:learning_curve_method_4_val_total_loss}{{c}{47}{損失の合計値\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces ネットワークB（Pretrained）における学習曲線\relax }}{47}{figure.caption.20}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_4_val_losses}{{4.8}{47}{ネットワークB（Pretrained）における学習曲線\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}客観評価2: 提案手法のさらなる検討}{48}{subsubsection.4.3.2}\protected@file@percent }
\newlabel{sec4:sec:obj_2}{{4.3.2}{48}{客観評価2: 提案手法のさらなる検討}{subsubsection.4.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces HuBERT Transformer層への入力特徴量を変化させた場合の比較\relax }}{48}{table.caption.22}\protected@file@percent }
\newlabel{sec4:tab:obj_weights_networkb_input_comparison}{{4.5}{48}{HuBERT Transformer層への入力特徴量を変化させた場合の比較\relax }{table.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces ネットワークAにおけるマルチタスク学習の有無による比較\relax }}{49}{table.caption.24}\protected@file@percent }
\newlabel{sec4:tab:obj_weights_networka_multitask}{{4.6}{49}{ネットワークAにおけるマルチタスク学習の有無による比較\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces ネットワークAからネットワークBまでを未学習の状態で初期化し，一度に学習させた場合の比較\relax }}{50}{table.caption.26}\protected@file@percent }
\newlabel{sec4:tab:obj_weights_e2e_randomized}{{4.7}{50}{ネットワークAからネットワークBまでを未学習の状態で初期化し，一度に学習させた場合の比較\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces ネットワークB（Randomized・A-SingleTask）かつ$\lambda _{\text  {HuB-disc}}= 0.1$の場合における学習済み重みでネットワークAとネットワークBを初期化し，一度に学習させた場合の比較\relax }}{50}{table.caption.28}\protected@file@percent }
\newlabel{sec4:tab:obj_weights_e2e_pretrained}{{4.8}{50}{ネットワークB（Randomized・A-SingleTask）かつ$\lossWeightHubDisc = 0.1$の場合における学習済み重みでネットワークAとネットワークBを初期化し，一度に学習させた場合の比較\relax }{table.caption.28}{}}
\newlabel{sec4:fig:learning_curve_method_6_val_mel_loss}{{4.9a}{51}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.23}{}}
\newlabel{sub@sec4:fig:learning_curve_method_6_val_mel_loss}{{a}{51}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.23}{}}
\newlabel{sec4:fig:learning_curve_method_6_val_ssl_feature_cluster_loss}{{4.9b}{51}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.23}{}}
\newlabel{sub@sec4:fig:learning_curve_method_6_val_ssl_feature_cluster_loss}{{b}{51}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.23}{}}
\newlabel{sec4:fig:learning_curve_method_6_val_total_loss}{{4.9c}{51}{損失の合計値\relax }{figure.caption.23}{}}
\newlabel{sub@sec4:fig:learning_curve_method_6_val_total_loss}{{c}{51}{損失の合計値\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces ネットワークB（Randomized・Mel-HuB）における学習曲線\relax }}{51}{figure.caption.23}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_6_val_losses}{{4.9}{51}{ネットワークB（Randomized・Mel-HuB）における学習曲線\relax }{figure.caption.23}{}}
\newlabel{sec4:fig:learning_curve_method_9_val_mel_loss}{{4.10a}{52}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.25}{}}
\newlabel{sub@sec4:fig:learning_curve_method_9_val_mel_loss}{{a}{52}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.25}{}}
\newlabel{sec4:fig:learning_curve_method_9_val_ssl_feature_cluster_loss}{{4.10b}{52}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.25}{}}
\newlabel{sub@sec4:fig:learning_curve_method_9_val_ssl_feature_cluster_loss}{{b}{52}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.25}{}}
\newlabel{sec4:fig:learning_curve_method_9_val_total_loss}{{4.10c}{52}{損失の合計値\relax }{figure.caption.25}{}}
\newlabel{sub@sec4:fig:learning_curve_method_9_val_total_loss}{{c}{52}{損失の合計値\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces ネットワークB（Randomized・A-SingleTask）における学習曲線\relax }}{52}{figure.caption.25}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_9_val_losses}{{4.10}{52}{ネットワークB（Randomized・A-SingleTask）における学習曲線\relax }{figure.caption.25}{}}
\newlabel{sec4:fig:learning_curve_method_7_val_mel_loss}{{4.11a}{53}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.27}{}}
\newlabel{sub@sec4:fig:learning_curve_method_7_val_mel_loss}{{a}{53}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.27}{}}
\newlabel{sec4:fig:learning_curve_method_7_val_ssl_feature_cluster_loss}{{4.11b}{53}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.27}{}}
\newlabel{sub@sec4:fig:learning_curve_method_7_val_ssl_feature_cluster_loss}{{b}{53}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.27}{}}
\newlabel{sec4:fig:learning_curve_method_7_val_total_loss}{{4.11c}{53}{損失の合計値\relax }{figure.caption.27}{}}
\newlabel{sub@sec4:fig:learning_curve_method_7_val_total_loss}{{c}{53}{損失の合計値\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces ネットワークE2E（Randomized）における学習曲線\relax }}{53}{figure.caption.27}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_7_val_losses}{{4.11}{53}{ネットワークE2E（Randomized）における学習曲線\relax }{figure.caption.27}{}}
\newlabel{sec4:fig:learning_curve_method_10_11_12_val_mel_loss}{{4.12a}{54}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.29}{}}
\newlabel{sub@sec4:fig:learning_curve_method_10_11_12_val_mel_loss}{{a}{54}{メルスペクトログラムについてのMAE Loss\relax }{figure.caption.29}{}}
\newlabel{sec4:fig:learning_curve_method_10_11_12_val_ssl_feature_cluster_loss}{{4.12b}{54}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.29}{}}
\newlabel{sub@sec4:fig:learning_curve_method_10_11_12_val_ssl_feature_cluster_loss}{{b}{54}{HuBERT離散特徴量についてのCross Entropy Loss\relax }{figure.caption.29}{}}
\newlabel{sec4:fig:learning_curve_method_10_11_12_val_total_loss}{{4.12c}{54}{損失の合計値\relax }{figure.caption.29}{}}
\newlabel{sub@sec4:fig:learning_curve_method_10_11_12_val_total_loss}{{c}{54}{損失の合計値\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces ネットワークE2E（Pretrained）における学習曲線\relax }}{54}{figure.caption.29}\protected@file@percent }
\newlabel{sec4:fig:learning_curve_method_10_11_12_val_losses}{{4.12}{54}{ネットワークE2E（Pretrained）における学習曲線\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}主観評価}{55}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces 主観評価実験における被験者の年齢層\relax }}{55}{figure.caption.30}\protected@file@percent }
\newlabel{sec4:fig:age}{{4.13}{55}{主観評価実験における被験者の年齢層\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces 主観評価実験の結果より計算した標本平均と95\%信頼区間\relax }}{56}{table.caption.31}\protected@file@percent }
\newlabel{sec4:tab:sbj_mean_ci}{{4.9}{56}{主観評価実験の結果より計算した標本平均と95\%信頼区間\relax }{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces 主観評価実験の結果より計算した平均値の差の検定におけるp値（明瞭性）\relax }}{56}{table.caption.32}\protected@file@percent }
\newlabel{sec4:tab:sbj_int_p}{{4.10}{56}{主観評価実験の結果より計算した平均値の差の検定におけるp値（明瞭性）\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}考察}{56}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}ネットワークB（Randomized）について}{56}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{sec4:sec:consideration_b_randomized}{{4.4.1}{56}{ネットワークB（Randomized）について}{subsubsection.4.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces 主観評価実験の結果より計算した平均値の差の検定におけるp値（類似性）\relax }}{57}{table.caption.33}\protected@file@percent }
\newlabel{sec4:tab:sbj_sim_p}{{4.11}{57}{主観評価実験の結果より計算した平均値の差の検定におけるp値（類似性）\relax }{table.caption.33}{}}
\citation{chen2018gradnorm}
\citation{liu2019end}
\citation{crawshaw2020multi}
\citation{yu2020gradient}
\citation{chen2022large}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}ネットワークB（Pretrained）について}{58}{subsubsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}結論}{60}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{謝辞}{61}{section*.34}\protected@file@percent }
\bibstyle{junsrt}
\bibdata{library}
\bibcite{shen2018natural}{1}
\bibcite{prajwal2020learning}{2}
\bibcite{kim2021lip}{3}
\bibcite{vaswani2017attention}{4}
\bibcite{gulati2020conformer}{5}
\bibcite{mira2022svts}{6}
\bibcite{kim2023lip_multitask}{7}
\bibcite{choi2023intelligible}{8}
\bibcite{hsu2021hubert}{9}
\bibcite{shi2022learning}{10}
\bibcite{afouras2018lrs3}{11}
\@writefile{toc}{\contentsline {section}{参考文献}{62}{section*.34}\protected@file@percent }
\bibcite{chung2018voxceleb2}{12}
\bibcite{maas2013rectifier}{13}
\bibcite{he2015delving}{14}
\bibcite{hendrycks2016gaussian}{15}
\bibcite{hochreiter1997long}{16}
\bibcite{cho2014learning}{17}
\bibcite{ioffe2015batch}{18}
\bibcite{ba2016layer}{19}
\bibcite{salimans2016weight}{20}
\bibcite{zhang2019gradient}{21}
\bibcite{srivastava2014dropout}{22}
\bibcite{kingma2014adam}{23}
\bibcite{loshchilov2017decoupled}{24}
\bibcite{higham2019deep}{25}
\bibcite{wan2018generalized}{26}
\bibcite{kong2020hifi}{27}
\bibcite{taguchi}{28}
\bibcite{esaki}{29}
\bibcite{atr}{30}
\bibcite{okamoto2023hi}{31}
\bibcite{takamichi2019jvs}{32}
\bibcite{bulat2017far}{33}
\bibcite{pasad2023comparative}{34}
\bibcite{nagrani2020voxceleb}{35}
\bibcite{panayotov2015librispeech}{36}
\bibcite{jia2018transfer}{37}
\bibcite{shi2022robust}{38}
\bibcite{snyder2015musan}{39}
\bibcite{afouras2018deep}{40}
\bibcite{yin2023reazonspeech}{41}
\bibcite{sawada2024release}{42}
\bibcite{radford2023robust}{43}
\bibcite{kirkland2023stuck}{44}
\bibcite{chen2018gradnorm}{45}
\bibcite{liu2019end}{46}
\bibcite{crawshaw2020multi}{47}
\bibcite{yu2020gradient}{48}
\bibcite{chen2022large}{49}
\gdef \@abspage@last{70}
