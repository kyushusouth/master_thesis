\begin{thebibliography}{10}

\bibitem{afouras2018lrs3}
Triantafyllos Afouras, Joon~Son Chung, and Andrew Zisserman.
\newblock Lrs3-ted: a large-scale dataset for visual speech recognition.
\newblock {\em arXiv preprint arXiv:1809.00496}, 2018.

\bibitem{chung2018voxceleb2}
Joon~Son Chung, Arsha Nagrani, and Andrew Zisserman.
\newblock Voxceleb2: Deep speaker recognition.
\newblock {\em arXiv preprint arXiv:1806.05622}, 2018.

\bibitem{shi2022learning}
Bowen Shi, Wei-Ning Hsu, Kushal Lakhotia, and Abdelrahman Mohamed.
\newblock Learning audio-visual speech representation by masked multimodal
  cluster prediction.
\newblock {\em arXiv preprint arXiv:2201.02184}, 2022.

\bibitem{zhu2023vatlm}
Qiushi Zhu, Long Zhou, Ziqiang Zhang, Shujie Liu, Binxing Jiao, Jie Zhang,
  Lirong Dai, Daxin Jiang, Jinyu Li, and Furu Wei.
\newblock Vatlm: Visual-audio-text pre-training with unified masked prediction
  for speech representation learning.
\newblock {\em IEEE Transactions on Multimedia}, 2023.

\bibitem{haliassos2022jointly}
Alexandros Haliassos, Pingchuan Ma, Rodrigo Mira, Stavros Petridis, and Maja
  Pantic.
\newblock Jointly learning visual and auditory speech representations from raw
  data.
\newblock {\em arXiv preprint arXiv:2212.06246}, 2022.

\bibitem{lian2023av}
Jiachen Lian, Alexei Baevski, Wei-Ning Hsu, and Michael Auli.
\newblock Av-data2vec: Self-supervised learning of audio-visual speech
  representations with contextualized target representations.
\newblock In {\em 2023 IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU)}, pp. 1--8. IEEE, 2023.

\bibitem{haliassos2024braven}
Alexandros Haliassos, Andreas Zinonos, Rodrigo Mira, Stavros Petridis, and Maja
  Pantic.
\newblock Braven: Improving self-supervised pre-training for visual and
  auditory speech recognition.
\newblock In {\em ICASSP 2024-2024 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 11431--11435. IEEE, 2024.

\bibitem{kim2023lip_multitask}
Minsu Kim, Joanna Hong, and Yong~Man Ro.
\newblock Lip-to-speech synthesis in the wild with multi-task learning.
\newblock In {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 1--5. IEEE, 2023.

\bibitem{choi2023intelligible}
Jeongsoo Choi, Minsu Kim, and Yong~Man Ro.
\newblock Intelligible lip-to-speech synthesis with speech units.
\newblock {\em arXiv preprint arXiv:2305.19603}, 2023.

\bibitem{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan
  Salakhutdinov, and Abdelrahman Mohamed.
\newblock Hubert: Self-supervised speech representation learning by masked
  prediction of hidden units.
\newblock {\em IEEE/ACM transactions on audio, speech, and language
  processing}, Vol.~29, pp. 3451--3460, 2021.

\bibitem{hsu2023revise}
Wei-Ning Hsu, Tal Remez, Bowen Shi, Jacob Donley, and Yossi Adi.
\newblock Revise: Self-supervised speech resynthesis with visual input for
  universal and generalized speech regeneration.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp. 18795--18805, 2023.

\bibitem{sahipjohn2023robustl2s}
Neha Sahipjohn, Neil Shah, Vishal Tambrahalli, and Vineet Gandhi.
\newblock Robustl2s: Speaker-specific lip-to-speech synthesis exploiting
  self-supervised representations.
\newblock In {\em 2023 Asia Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA ASC)}, pp. 1492--1499. IEEE,
  2023.

\bibitem{yeo2024akvsr}
Jeong~Hun Yeo, Minsu Kim, Jeongsoo Choi, Dae~Hoe Kim, and Yong~Man Ro.
\newblock Akvsr: Audio knowledge empowered visual speech recognition by
  compressing audio knowledge of a pretrained model.
\newblock {\em IEEE Transactions on Multimedia}, 2024.

\bibitem{cheng2023opensr}
Xize Cheng, Tao Jin, Linjun Li, Wang Lin, Xinyu Duan, and Zhou Zhao.
\newblock Opensr: Open-modality speech recognition via maintaining
  multi-modality alignment.
\newblock {\em arXiv preprint arXiv:2306.06410}, 2023.

\bibitem{djilali2023lip2vec}
Yasser Abdelaziz~Dahou Djilali, Sanath Narayan, Haithem Boussaid, Ebtessam
  Almazrouei, and Merouane Debbah.
\newblock Lip2vec: Efficient and robust visual speech recognition via
  latent-to-latent visual to audio representation mapping.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp. 13790--13801, 2023.

\bibitem{liu2023synthvsr}
Xubo Liu, Egor Lakomkin, Konstantinos Vougioukas, Pingchuan Ma, Honglie Chen,
  Ruiming Xie, Morrie Doulaty, Niko Moritz, Jachym Kolar, Stavros Petridis,
  et~al.
\newblock Synthvsr: Scaling up visual speech recognition with synthetic
  supervision.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp. 18806--18815, 2023.

\bibitem{ma2023auto}
Pingchuan Ma, Alexandros Haliassos, Adriana Fernandez-Lopez, Honglie Chen,
  Stavros Petridis, and Maja Pantic.
\newblock Auto-avsr: Audio-visual speech recognition with automatic labels.
\newblock In {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 1--5. IEEE, 2023.

\bibitem{chang2024conformer}
Oscar Chang, Hank Liao, Dmitriy Serdyuk, Ankit Shahy, and Olivier Siohan.
\newblock Conformer is all you need for visual speech recognition.
\newblock In {\em ICASSP 2024-2024 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 10136--10140. IEEE, 2024.

\bibitem{zinonos2023learning}
Andreas Zinonos, Alexandros Haliassos, Pingchuan Ma, Stavros Petridis, and Maja
  Pantic.
\newblock Learning cross-lingual visual speech representations.
\newblock In {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 1--5. IEEE, 2023.

\bibitem{ephrat2018looking}
Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan
  Hassidim, William~T Freeman, and Michael Rubinstein.
\newblock Looking to listen at the cocktail party: A speaker-independent
  audio-visual model for speech separation.
\newblock {\em arXiv preprint arXiv:1804.03619}, 2018.

\bibitem{salesky2021multilingual}
Elizabeth Salesky, Matthew Wiesner, Jacob Bremerman, Roldano Cattoni, Matteo
  Negri, Marco Turchi, Douglas~W Oard, and Matt Post.
\newblock The multilingual tedx corpus for speech recognition and translation.
\newblock {\em arXiv preprint arXiv:2102.01757}, 2021.

\bibitem{zhao2019cascade}
Ya~Zhao, Rui Xu, and Mingli Song.
\newblock A cascade sequence-to-sequence model for chinese mandarin lip
  reading.
\newblock In {\em Proceedings of the 1st ACM International Conference on
  Multimedia in Asia}, pp. 1--6, 2019.

\bibitem{kim2023lip_vsr}
Minsu Kim, Jeong~Hun Yeo, Jeongsoo Choi, and Yong~Man Ro.
\newblock Lip reading for low-resource languages by learning and combining
  general speech knowledge and language-specific knowledge.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp. 15359--15371, 2023.

\bibitem{yeo2023visual}
Jeong~Hun Yeo, Minsu Kim, Shinji Watanabe, and Yong~Man Ro.
\newblock Visual speech recognition for low-resource languages with automatic
  labels from whisper model.
\newblock {\em arXiv preprint arXiv:2309.08535}, 2023.

\bibitem{taguchi}
田口史郎.
\newblock "深層学習を用いたデータ駆動型調音・音声間変換に関する研究".
\newblock 九州大学大学院芸術工学府芸術工学専攻 博士論文, 2021.

\bibitem{esaki}
江崎蓮.
\newblock "深層学習を用いた口唇動画・音声変換に関する調査".
\newblock 九州大学大学院芸術工学府芸術工学専攻 修士論文, 2022.

\bibitem{kim2024let}
Ji-Hoon Kim, Jaehun Kim, and Joon~Son Chung.
\newblock Let there be sound: Reconstructing high quality speech from silent
  videos.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, Vol.~38, pp. 2759--2767, 2024.

\bibitem{hochreiter1997long}
S~Hochreiter.
\newblock Long short-term memory.
\newblock {\em Neural Computation MIT-Press}, 1997.

\bibitem{cho2014learning}
Kyunghyun Cho.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{vaswani2017attention}
A~Vaswani.
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 2017.

\bibitem{kingma2014adam}
Diederik~P Kingma.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{loshchilov2017decoupled}
I~Loshchilov.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{ioffe2015batch}
Sergey Ioffe.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock {\em arXiv preprint arXiv:1502.03167}, 2015.

\bibitem{ba2016layer}
Jimmy~Lei Ba.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{salimans2016weight}
Tim Salimans and Durk~P Kingma.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock {\em Advances in neural information processing systems}, Vol.~29, ,
  2016.

\bibitem{srivastava2014dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em The journal of machine learning research}, Vol.~15, No.~1, pp.
  1929--1958, 2014.

\bibitem{wan2018generalized}
Li~Wan, Quan Wang, Alan Papir, and Ignacio~Lopez Moreno.
\newblock Generalized end-to-end loss for speaker verification.
\newblock In {\em 2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp. 4879--4883. IEEE, 2018.

\bibitem{kong2020hifi}
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.
\newblock Hifi-gan: Generative adversarial networks for efficient and high
  fidelity speech synthesis.
\newblock {\em Advances in neural information processing systems}, Vol.~33, pp.
  17022--17033, 2020.

\bibitem{atr}
Yoshinori Sagisaka, Kazuya Takeda, M~Abel, Shigeru Katagiri, Tetsuo Umeda, and
  Hisao Kuwabara.
\newblock A large-scale japanese speech database.
\newblock In {\em ICSLP}, pp. 1089--1092, 1990.

\bibitem{okamoto2023hi}
T~Okamoto, Y~Shiga, and H~Kawai.
\newblock Hi-fi-captain: High-fidelity and high-capacity conversational speech
  synthesis corpus developed by nict, 2023.

\bibitem{takamichi2019jvs}
Shinnosuke Takamichi, Kentaro Mitsui, Yuki Saito, Tomoki Koriyama, Naoko Tanji,
  and Hiroshi Saruwatari.
\newblock Jvs corpus: free japanese multi-speaker voice corpus.
\newblock {\em arXiv preprint arXiv:1908.06248}, 2019.

\bibitem{bulat2017far}
Adrian Bulat and Georgios Tzimiropoulos.
\newblock How far are we from solving the 2d \& 3d face alignment problem?(and
  a dataset of 230,000 3d facial landmarks).
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pp. 1021--1030, 2017.

\bibitem{rinna-japanese-hubert-base}
Yukiya Hono, Kentaro Mitsui, and Kei Sawada.
\newblock rinna/japanese-hubert-base.

\bibitem{sawada2024release}
Kei Sawada, Tianyu Zhao, Makoto Shing, Kentaro Mitsui, Akio Kaga, Yukiya Hono,
  Toshiaki Wakatsuki, and Koh Mitsuda.
\newblock Release of pre-trained models for the {J}apanese language.
\newblock In {\em Proceedings of the 2024 Joint International Conference on
  Computational Linguistics, Language Resources and Evaluation (LREC-COLING
  2024)}, pp. 13898--13905, 5 2024.
\newblock Available at: https://arxiv.org/abs/2404.01657.

\bibitem{pasad2023comparative}
Ankita Pasad, Bowen Shi, and Karen Livescu.
\newblock Comparative layer-wise analysis of self-supervised speech models.
\newblock In {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp. 1--5. IEEE, 2023.

\bibitem{radford2023robust}
Alec Radford, Jong~Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
  Ilya Sutskever.
\newblock Robust speech recognition via large-scale weak supervision.
\newblock In {\em International conference on machine learning}, pp.
  28492--28518. PMLR, 2023.

\bibitem{kirkland2023stuck}
Ambika Kirkland, Shivam Mehta, Harm Lameris, Gustav~Eje Henter, Eva
  Sz{\'e}kely, and Joakim Gustafson.
\newblock Stuck in the mos pit: A critical analysis of mos test methodology in
  tts evaluation.
\newblock In {\em 12th Speech Synthesis Workshop (SSW) 2023}, 2023.

\bibitem{wester2015we}
Mirjam Wester, Cassia Valentini-Botinhao, and Gustav~Eje Henter.
\newblock Are we using enough listeners? no! an empirically-supported critique
  of interspeech 2014 tts evaluations.
\newblock In {\em Interspeech 2015}, pp. 3476--3480. International Speech
  Communication Association, 2015.

\end{thebibliography}
