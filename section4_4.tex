\subsection{考察}
\subsubsection{ネットワークB（Randomized）について}
まず，ネットワークB（Randomized）は客観評価において，ネットワークB（Randomized・Mel-HuB）を上回る性能を示した．これより，ネットワークBへの入力として，HuBERT中間特徴量はメルスペクトログラムとHuBERT離散特徴量に対するロジットを組み合わせた特徴量よりも優れていたと考えられる．HuBERT中間特徴量は，音声波形を入力とする畳み込みエンコーダの出力であり，Masked PredictionにおいてTransformer層の入力となる．従って，畳み込みエンコーダは音声波形の系列長を圧縮しつつ、文脈構造を考慮するための情報を効率的に詰め込むよう最適化されると考えられる．よって，ネットワークB（Randomized）におけるHuBERT Transformer層はランダム初期化されてはいたものの，HuBERT中間特徴量自体が文脈的構造の考慮に適した情報を含んでいるために，メルスペクトログラムとHuBERT離散特徴量に対するロジットを入力特徴量とする場合よりも特徴抽出が行いやすくなったことで，高い性能に達したと考えられる．

次に，ネットワークB（Randomized・A-SingleTask）は客観評価と主観評価の両面において，ネットワークB（Randomized）を上回る性能を示した．これより，HuBERT中間特徴量を予測するネットワークAは，メルスペクトログラムとHuBERT離散特徴量を同時に予測するマルチタスク学習を行わず，HuBERT中間特徴量のみを予測するよう学習した方が、ネットワークBに対するより良い入力特徴量を与えられると考えられる．ここで，ネットワークB（Randomized）とネットワークB（Randomized・Mel-HuB）の結果より，HuBERT中間特徴量は，メルスペクトログラムとHuBERT離散特徴量のロジットから構成した特徴量と比較して，ネットワークBの予測精度改善につながるより良い入力特徴量であった．よって，HuBERT中間特徴量と，メルスペクトログラムおよびHuBERT離散特徴量は，異なる情報を含んだ特徴量だと考えられ，マルチタスク学習における損失の干渉が悪影響を及ぼしたと考えられる．

最後に，ネットワークE2E（Pretrained）は客観評価において，ネットワークB（Randomized・A-SingleTask）を上回ることはできなかった．これより，HuBERT中間特徴量を継ぎ目として2段階で学習したことは，ネットワーク全体としての表現力を損なうものではなかったと考えられる。HuBERT中間特徴量は元々DNNの中間表現であったため、2つのネットワーク間の継ぎ目として利用しても，十分な表現力を維持できたと考えられる。

\subsubsection{ネットワークB（Pretrained）について}
ネットワークB（Pretrained）は客観評価において、ネットワークB（Randomized）に劣る結果となった．特に，話者類似度の低下が顕著であった．しかし，これはHuBERTの事前学習済み重みが話者性の抽出に適していなかったわけではないと考える．実際，話者識別の先行研究\cite{chen2022large}では，音声波形をHuBERTによって変換した特徴量を入力として話者識別モデルを学習させた場合，窓長\SI{25}{\ms}，シフト幅\SI{10}{\ms}で計算された40次元のメルスペクトログラムを入力とする場合よりも，Equal Error Rateが低いことが示されている．ここで，HuBERTは事前学習後のまま重みを固定し，単なる特徴抽出器として用いられた．話者性の含まれるメルスペクトログラムに対し，話者識別をより高い精度で行える入力特徴量を音声波形から抽出できたことになるから，HuBERTが話者性抽出に適していないわけではないと考える．また，本研究ではHuBERT Transformer層の出力に話者ベクトルを結合する構成としたため，仮に話者性が損なわれていたとしてもそれを補完できたのではないかと考える．

これに対し，ネットワークB（Pretrained）が有効性を示さなかった理由は2つ考えられる．1つ目は，損失関数の重み係数$\lossWeightHubDisc$の適切な値が，グリッドサーチした範囲に存在しなかったことである．ネットワークB（Randomized）では適切な値が含まれていたが，グリッドサーチの候補は決め打ちであるから，その探索範囲に限界があった．2つ目は，事前学習時との入力特徴量のギャップである．本実験では，HuBERTの事前学習に合わせてHuBERT中間特徴量をTransformer層への入力とした．しかし，事前学習時に用いられるマスクベクトルが存在しなかったこと，原音声から得られる特徴量が存在しなかったことがギャップとなり、転移学習の妨げになった可能性がある．

\subsection{今後の課題}
本実験を通して得られた今後の課題は2つある．

1つ目は，損失関数の重み係数$\lossWeightHubDisc$におけるグリッドサーチである．本実験では5種類の値によるグリッドサーチを行い，客観評価の結果から，検討した手法の性能は$\lossWeightHubDisc$に大きく左右されることがわかった．よって，実数値をとる重み係数に対して候補点を決めたグリッドサーチは，モデルの性能の妨げになると考えられる．この課題に対して，各タスクに対する損失関数の勾配のノルムを損失の下がり具合によって調整するGradNorm\cite{chen2018gradnorm}や，よりシンプルに損失の下がり具合のみを用いるDynamic Weight Averaging\cite{liu2019end}により，損失関数の重み係数に対する動的な調整が検討可能である．

2つ目は，HuBERT Transformer層の転移学習方法である．本実験では，事前学習時との入力特徴量のギャップが大きかったことが課題の一つとして考えられる．これに対し，学習初期にあえて原音声から得られる特徴量を混入させて事前学習時の条件に近づけ，徐々に混入率を下げてネットワークAによる予測結果のみを入力とするようスケジューリングする方法が考えられる．混入率を下げて事前学習時から徐々に離していくことは，学習難易度が徐々に高まっていくことに相当する．このような方法はカリキュラム学習と呼ばれ，難易度を下げた場合において収束した局所解が，その後難易度を上げた場合における良い初期値となることで，初めから難易度の高い学習を行うよりも良い局所解に収束させられる可能性がある\cite{wang2021survey}．
