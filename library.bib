@article{taguchi,
  author  = {田口史郎},
  journal = {九州大学大学院芸術工学府芸術工学専攻 博士論文},
  number  = {},
  title   = {"深層学習を用いたデータ駆動型調音・音声間変換に関する研究"},
  volume  = {},
  year    = {2021}
}
@article{esaki,
  author  = {江崎蓮},
  journal = {九州大学大学院芸術工学府芸術工学専攻 修士論文},
  number  = {},
  title   = {"深層学習を用いた口唇動画・音声変換に関する調査"},
  volume  = {},
  year    = {2022}
}
@article{fujita,
  author  = {藤田直明},
  journal = {九州大学大学院芸術工学府芸術工学専攻 修士論文},
  number  = {},
  title   = {"少量データ条件下での口唇動画・音声変換に関する検討"},
  volume  = {},
  year    = {2024}
}

@inproceedings{atr,
  title={A large-scale Japanese speech database.},
  author={Sagisaka, Yoshinori and Takeda, Kazuya and Abel, M and Katagiri, Shigeru and Umeda, Tetsuo and Kuwabara, Hisao},
  booktitle={ICSLP},
  pages={1089--1092},
  year={1990}
}
@misc{okamoto2023hi,
  title={Hi-Fi-CAPTAIN: High-fidelity and high-capacity conversational speech synthesis corpus developed by NICT},
  author={Okamoto, T and Shiga, Y and Kawai, H},
  year={2023}
}
@article{takamichi2019jvs,
  title={JVS corpus: free Japanese multi-speaker voice corpus},
  author={Takamichi, Shinnosuke and Mitsui, Kentaro and Saito, Yuki and Koriyama, Tomoki and Tanji, Naoko and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:1908.06248},
  year={2019}
}
@article{afouras2018lrs3,
  title={LRS3-TED: a large-scale dataset for visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1809.00496},
  year={2018}
}
@article{nagrani2020voxceleb,
  title={Voxceleb: Large-scale speaker verification in the wild},
  author={Nagrani, Arsha and Chung, Joon Son and Xie, Weidi and Zisserman, Andrew},
  journal={Computer Speech \& Language},
  volume={60},
  pages={101027},
  year={2020},
  publisher={Elsevier}
}
@article{chung2018voxceleb2,
  title={Voxceleb2: Deep speaker recognition},
  author={Chung, Joon Son and Nagrani, Arsha and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1806.05622},
  year={2018}
}
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}
@article{ephrat2018looking,
  title={Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation},
  author={Ephrat, Ariel and Mosseri, Inbar and Lang, Oran and Dekel, Tali and Wilson, Kevin and Hassidim, Avinatan and Freeman, William T and Rubinstein, Michael},
  journal={arXiv preprint arXiv:1804.03619},
  year={2018}
}
@article{salesky2021multilingual,
  title={The multilingual tedx corpus for speech recognition and translation},
  author={Salesky, Elizabeth and Wiesner, Matthew and Bremerman, Jacob and Cattoni, Roldano and Negri, Matteo and Turchi, Marco and Oard, Douglas W and Post, Matt},
  journal={arXiv preprint arXiv:2102.01757},
  year={2021}
}
@inproceedings{zhao2019cascade,
  title={A cascade sequence-to-sequence model for chinese mandarin lip reading},
  author={Zhao, Ya and Xu, Rui and Song, Mingli},
  booktitle={Proceedings of the 1st ACM International Conference on Multimedia in Asia},
  pages={1--6},
  year={2019}
}

@inproceedings{wan2018generalized,
  title={Generalized end-to-end loss for speaker verification},
  author={Wan, Li and Wang, Quan and Papir, Alan and Moreno, Ignacio Lopez},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4879--4883},
  year={2018},
  organization={IEEE}
}
@misc{rinna-japanese-hubert-base,
    title = {rinna/japanese-hubert-base},
    author = {Hono, Yukiya and Mitsui, Kentaro and Sawada, Kei},
    url = {https://huggingface.co/rinna/japanese-hubert-base}
}
@inproceedings{sawada2024release,
    title = {Release of Pre-Trained Models for the {J}apanese Language},
    author = {Sawada, Kei and Zhao, Tianyu and Shing, Makoto and Mitsui, Kentaro and Kaga, Akio and Hono, Yukiya and Wakatsuki, Toshiaki and Mitsuda, Koh},
    booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
    month = {5},
    year = {2024},
    pages = {13898--13905},
    url = {https://aclanthology.org/2024.lrec-main.1213},
    note = {Available at: https://arxiv.org/abs/2404.01657}
}
@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}
@inproceedings{kim2023lip_multitask,
  title={Lip-to-speech synthesis in the wild with multi-task learning},
  author={Kim, Minsu and Hong, Joanna and Ro, Yong Man},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@article{choi2023intelligible,
  title={Intelligible lip-to-speech synthesis with speech units},
  author={Choi, Jeongsoo and Kim, Minsu and Ro, Yong Man},
  journal={arXiv preprint arXiv:2305.19603},
  year={2023}
}
@inproceedings{hsu2023revise,
  title={Revise: Self-supervised speech resynthesis with visual input for universal and generalized speech regeneration},
  author={Hsu, Wei-Ning and Remez, Tal and Shi, Bowen and Donley, Jacob and Adi, Yossi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18795--18805},
  year={2023}
}
@inproceedings{sahipjohn2023robustl2s,
  title={RobustL2S: Speaker-Specific Lip-to-Speech Synthesis exploiting Self-Supervised Representations},
  author={Sahipjohn, Neha and Shah, Neil and Tambrahalli, Vishal and Gandhi, Vineet},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={1492--1499},
  year={2023},
  organization={IEEE}
}
@inproceedings{kim2024let,
  title={Let There Be Sound: Reconstructing High Quality Speech from Silent Videos},
  author={Kim, Ji-Hoon and Kim, Jaehun and Chung, Joon Son},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={3},
  pages={2759--2767},
  year={2024}
}
@inproceedings{djilali2023lip2vec,
  title={Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping},
  author={Djilali, Yasser Abdelaziz Dahou and Narayan, Sanath and Boussaid, Haithem and Almazrouei, Ebtessam and Debbah, Merouane},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13790--13801},
  year={2023}
}
@article{yeo2024akvsr,
  title={Akvsr: Audio knowledge empowered visual speech recognition by compressing audio knowledge of a pretrained model},
  author={Yeo, Jeong Hun and Kim, Minsu and Choi, Jeongsoo and Kim, Dae Hoe and Ro, Yong Man},
  journal={IEEE Transactions on Multimedia},
  year={2024},
  publisher={IEEE}
}
@article{cheng2023opensr,
  title={Opensr: Open-modality speech recognition via maintaining multi-modality alignment},
  author={Cheng, Xize and Jin, Tao and Li, Linjun and Lin, Wang and Duan, Xinyu and Zhao, Zhou},
  journal={arXiv preprint arXiv:2306.06410},
  year={2023}
}
@inproceedings{liu2023synthvsr,
  title={Synthvsr: Scaling up visual speech recognition with synthetic supervision},
  author={Liu, Xubo and Lakomkin, Egor and Vougioukas, Konstantinos and Ma, Pingchuan and Chen, Honglie and Xie, Ruiming and Doulaty, Morrie and Moritz, Niko and Kolar, Jachym and Petridis, Stavros and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18806--18815},
  year={2023}
}
@inproceedings{ma2023auto,
  title={Auto-avsr: Audio-visual speech recognition with automatic labels},
  author={Ma, Pingchuan and Haliassos, Alexandros and Fernandez-Lopez, Adriana and Chen, Honglie and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@inproceedings{chang2024conformer,
  title={Conformer is All You Need for Visual Speech Recognition},
  author={Chang, Oscar and Liao, Hank and Serdyuk, Dmitriy and Shahy, Ankit and Siohan, Olivier},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={10136--10140},
  year={2024},
  organization={IEEE}
}
@article{yeo2024visual,
  title={Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing},
  author={Yeo, Jeong Hun and Han, Seunghee and Kim, Minsu and Ro, Yong Man},
  journal={arXiv preprint arXiv:2402.15151},
  year={2024}
}
@inproceedings{zinonos2023learning,
  title={Learning cross-lingual visual speech representations},
  author={Zinonos, Andreas and Haliassos, Alexandros and Ma, Pingchuan and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@article{yeo2023visual,
  title={Visual speech recognition for low-resource languages with automatic labels from whisper model},
  author={Yeo, Jeong Hun and Kim, Minsu and Watanabe, Shinji and Ro, Yong Man},
  journal={arXiv preprint arXiv:2309.08535},
  year={2023}
}
@inproceedings{kim2023lip_vsr,
  title={Lip reading for low-resource languages by learning and combining general speech knowledge and language-specific knowledge},
  author={Kim, Minsu and Yeo, Jeong Hun and Choi, Jeongsoo and Ro, Yong Man},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15359--15371},
  year={2023}
}
@article{kim2024multilingual,
  title={Multilingual visual speech recognition with a single model by learning with discrete visual speech units},
  author={Kim, Minsu and Yeo, Jeong Hun and Choi, Jeongsoo and Park, Se Jin and Ro, Yong Man},
  journal={arXiv preprint arXiv:2401.09802},
  year={2024}
}
@inproceedings{lian2023av,
  title={Av-data2vec: Self-supervised learning of audio-visual speech representations with contextualized target representations},
  author={Lian, Jiachen and Baevski, Alexei and Hsu, Wei-Ning and Auli, Michael},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}
@article{zhu2023vatlm,
  title={Vatlm: Visual-audio-text pre-training with unified masked prediction for speech representation learning},
  author={Zhu, Qiushi and Zhou, Long and Zhang, Ziqiang and Liu, Shujie and Jiao, Binxing and Zhang, Jie and Dai, Lirong and Jiang, Daxin and Li, Jinyu and Wei, Furu},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  publisher={IEEE}
}
@article{haliassos2022jointly,
  title={Jointly learning visual and auditory speech representations from raw data},
  author={Haliassos, Alexandros and Ma, Pingchuan and Mira, Rodrigo and Petridis, Stavros and Pantic, Maja},
  journal={arXiv preprint arXiv:2212.06246},
  year={2022}
}
@article{shi2022learning,
  title={Learning audio-visual speech representation by masked multimodal cluster prediction},
  author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2201.02184},
  year={2022}
}
@inproceedings{haliassos2024braven,
  title={BRAVEn: Improving Self-supervised pre-training for Visual and Auditory Speech Recognition},
  author={Haliassos, Alexandros and Zinonos, Andreas and Mira, Rodrigo and Petridis, Stavros and Pantic, Maja},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={11431--11435},
  year={2024},
  organization={IEEE}
}
@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}
@inproceedings{bulat2017far,
  title={How far are we from solving the 2d \& 3d face alignment problem?(and a dataset of 230,000 3d facial landmarks)},
  author={Bulat, Adrian and Tzimiropoulos, Georgios},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1021--1030},
  year={2017}
}
@inproceedings{rix2001perceptual,
  title={Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs},
  author={Rix, Antony W and Beerends, John G and Hollier, Michael P and Hekstra, Andries P},
  booktitle={2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221)},
  volume={2},
  pages={749--752},
  year={2001},
  organization={IEEE}
}
@inproceedings{taal2010short,
  title={A short-time objective intelligibility measure for time-frequency weighted noisy speech},
  author={Taal, Cees H and Hendriks, Richard C and Heusdens, Richard and Jensen, Jesper},
  booktitle={2010 IEEE international conference on acoustics, speech and signal processing},
  pages={4214--4217},
  year={2010},
  organization={IEEE}
}
@article{taal2011algorithm,
  title={An algorithm for intelligibility prediction of time--frequency weighted noisy speech},
  author={Taal, Cees H and Hendriks, Richard C and Heusdens, Richard and Jensen, Jesper},
  journal={IEEE Transactions on audio, speech, and language processing},
  volume={19},
  number={7},
  pages={2125--2136},
  year={2011},
  publisher={IEEE}
}
@inproceedings{wester2015we,
  title={Are we using enough listeners? No! An empirically-supported critique of Interspeech 2014 TTS evaluations},
  author={Wester, Mirjam and Valentini-Botinhao, Cassia and Henter, Gustav Eje},
  booktitle={Interspeech 2015},
  pages={3476--3480},
  year={2015},
  organization={International Speech Communication Association}
}
@inproceedings{dall2014rating,
  title={Rating naturalness in speech synthesis: The effect of style and expectation},
  author={Dall, Rasmus and Yamagishi, Junichi and King, Simon},
  booktitle={Proceedings of Speech Prosody},
  year={2014},
  organization={Citeseer}
}
@inproceedings{kirkland2023stuck,
  title={Stuck in the MOS pit: A critical analysis of MOS test methodology in TTS evaluation},
  author={Kirkland, Ambika and Mehta, Shivam and Lameris, Harm and Henter, Gustav Eje and Sz{\'e}kely, Eva and Gustafson, Joakim},
  booktitle={12th Speech Synthesis Workshop (SSW) 2023},
  year={2023}
}
@article{king2008blizzard,
  title={The blizzard challenge 2008},
  author={King, Simon and Clark, Robert AJ and Mayo, Catherine and Karaiskos, Vasilis},
  year={2008}
}
@inproceedings{pasad2023comparative,
  title={Comparative layer-wise analysis of self-supervised speech models},
  author={Pasad, Ankita and Shi, Bowen and Livescu, Karen},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@article{saeki2022utmos,
  title={Utmos: Utokyo-sarulab system for voicemos challenge 2022},
  author={Saeki, Takaaki and Xin, Detai and Nakata, Wataru and Koriyama, Tomoki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2204.02152},
  year={2022}
}
@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}
@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}
@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}
@article{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}
@inproceedings{maas2013rectifier,
  title={Rectifier nonlinearities improve neural network acoustic models},
  author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y and others},
  booktitle={Proc. icml},
  volume={30},
  number={1},
  pages={3},
  year={2013},
  organization={Atlanta, GA}
}
@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}
@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@article{zhang2019gradient,
  title={Gradient descent based optimization algorithms for deep learning models training},
  author={Zhang, Jiawei},
  journal={arXiv preprint arXiv:1903.03614},
  year={2019}
}
@article{higham2019deep,
  title={Deep learning: An introduction for applied mathematicians},
  author={Higham, Catherine F and Higham, Desmond J},
  journal={Siam review},
  volume={61},
  number={4},
  pages={860--891}, 
  year={2019},
  publisher={SIAM}
}
@article{shi2022robust,
  title={Robust self-supervised audio-visual speech recognition},
  author={Shi, Bowen and Hsu, Wei-Ning and Mohamed, Abdelrahman},
  journal={arXiv preprint arXiv:2201.01763},
  year={2022}
}
@inproceedings{ma2022training,
  title={Training strategies for improved lip-reading},
  author={Ma, Pingchuan and Wang, Yujiang and Petridis, Stavros and Shen, Jie and Pantic, Maja},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8472--8476},
  year={2022},
  organization={IEEE}
}
@article{jia2018transfer,
  title={Transfer learning from speaker verification to multispeaker text-to-speech synthesis},
  author={Jia, Ye and Zhang, Yu and Weiss, Ron and Wang, Quan and Shen, Jonathan and Ren, Fei and Nguyen, Patrick and Pang, Ruoming and Lopez Moreno, Ignacio and Wu, Yonghui and others},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{chen2022large,
  title={Large-scale self-supervised speech representation learning for automatic speaker verification},
  author={Chen, Zhengyang and Chen, Sanyuan and Wu, Yu and Qian, Yao and Wang, Chengyi and Liu, Shujie and Qian, Yanmin and Zeng, Michael},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6147--6151},
  year={2022},
  organization={IEEE}
}
@inproceedings{chen2018gradnorm,
  title={Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks},
  author={Chen, Zhao and Badrinarayanan, Vijay and Lee, Chen-Yu and Rabinovich, Andrew},
  booktitle={International conference on machine learning},
  pages={794--803},
  year={2018},
  organization={PMLR}
}
@inproceedings{liu2019end,
  title={End-to-end multi-task learning with attention},
  author={Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1871--1880},
  year={2019}
}
@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}