\section{序論}
\subsection{背景}
音声は基本的なコミュニケーション手段として，人々の日常生活において重要な役割を果たしている．しかし，癌などの病気で喉頭を摘出すると，声帯振動による音声生成が不可能になり，従来の発声手段を失う．このような場合の代用音声手法として，電気式人工喉頭や食道発声，シャント発声があるが，自然で聞き取りやすい音声を生成することが難しかったり，習得に訓練を必要としたり，器具の交換のための定期的な手術を必要とするといった課題がある．これに対して本研究では，新たな代用音声手法として，深層学習を活用して口唇の動きと音声波形の関係性を学習することで，口唇の動きから音声を合成するアプローチを提案する．この手法により，訓練や手術を必要とせずとも，自然な声でのコミュニケーションを可能にすることを目指す．

% 音声は基本的なコミュニケーションの手段であり，人と人とのコミュニケーションの場面において，重要な役割を果たしている．音声は，肺からの呼気流による声帯の振動が音源波を生成し，声道特性に伴ったフィルタリングと口唇からの放射特性に従って生成される．これより，音声の生成には音源を作り出す声帯やその制御のための喉頭，舌や口唇といった調音器官の働きが重要となる．しかし，癌などの重い病気で喉頭を摘出した場合，音源波を生成することができなくなるため，これまで通り発声を行うことが不可能になってしまう．このようなコミュニケーション機能の喪失に対し，現在でも電気式人工喉頭や食道発声，シャント発声といった代用音声手法が存在する．電気式人工喉頭では，専用の発振器を顎下に当てて振動を加えることにより，それを音源とした発声を行う．発振器を用意すれば容易に発声することが可能であるが，生成される音声のピッチが発振器の振動に依存してしまうため，抑揚のない単調な音声になってしまう．食道発声では，まず口や鼻から食道内に空気を取り込み，その空気を逆流させることで食道入口部の粘膜を振動させることによって発声する．電気式人工喉頭と違って道具を必要とせず，ピッチも本人が調節できるが，その習得に長期間の訓練を要する．シャント発声では，手術によって気管と食道を繋ぐ管を設ける．これにより，息を吐き出す際に設けられた喉の穴を手で塞ぐことによって肺からの呼気流が食道に流れる．そのため，食道発声と同様に粘膜の振動を音源とし，発声することが可能となる．習得は容易であり，比較的自然に話すことが可能となるが，設けられた管を交換するための定期的な手術が必要となる．このように，現在用いられている代用音声手法にはそれぞれデメリットが存在する．

% これに対し，本研究ではビデオカメラで撮影した口唇の動きから音声合成を行うことによる，新たな代用音声手法を検討する．本来，音声は声帯の振動や声道の形状に依存して生成されるものであり，口唇の動きのみから音声波形を直接推定することは困難である．そこで，近年画像や自然言語処理，音声といった分野において成果を上げている深層学習を活用し，口唇の動きと音声の間の関係を学習することで推定を行う．これにより，従来の代用音声手法よりも自然性の高い音声を，訓練や定期的な手術の必要なく提供することを目指す．

% これまでの動画音声合成は英語が中心に検討が進んでおり，近年ではYouTube上のデータを収集，処理することによって構築した大規模データセット\cite{afouras2018lrs3,chung2018voxceleb2}を用いることで，大規模で表現力の高いモデルが構築可能となっている．特に，従来行われてきた教師あり学習のみならず，動画と音声の関係性を自己教師あり学習（Self Supervised Learning; SSL）によって学習し，そのモデルを動画音声合成や，動画からテキストを推定するVisual Speech Recognition（VSR）にFineTuningするアプローチが提案され，その有効性が示されている．自己教師あり学習モデルにもいくつかの種類があり，近年多くの研究で応用例のあるAVHuBERT\cite{shi2022learning}は，動画・音声の入力領域においてマスクされた区間の予測と，予測対象の更新を繰り返して学習を進めていくモデルである．予測対象の更新は5回行われ，1回目は音声波形から計算されるMFCCをクラスタリングした結果を利用するが，2回目以降はモデルの中間特徴量をクラスタリングした結果を新たな予測対象に設定する．更新のたびに再度モデルをランダム初期化して再学習するが，その予測対象の複雑さが増していくことによって，学習が促進されるようなメカニズムとなっている．また，これに類似したVATLM\cite{zhu2023vatlm}は，動画と音声のみならずテキストも加えた学習によって，精度改善を達成した．その他，StudentとTeacherという2つのネットワークを利用し，Teacherから出力される特徴量をStudentがマスクされた入力から予測することによって学習を進めるRAVEn\cite{haliassos2022jointly}やAV-data2vec\cite{lian2023av}，RAVEnの改善版として提案されたBRAVEn\cite{haliassos2024braven}など，多くのモデルが提案されている．

近年の動画音声合成では，LRS3\cite{afouras2018lrs3}やVoxCeleb2\cite{chung2018voxceleb2}などの大規模データセットを活用して構築された，自己教師あり学習（Self Supervised Learning; SSL）モデルをFineTuningすることの有効性が示されている．特に，近年の動画音声合成においてはAVHuBERT\cite{shi2022learning}というモデルが動画からの特徴抽出器として採用される場合が多い．AVHuBERTは，動画と音声の対応関係をMasked Predictionという自己教師あり学習方法により捉えたモデルであり，Modality Dropoutという工夫により，自己教師あり学習時には動画と音声の両方を入力とするものの，FineTuning時には動画あるいは音声のみを入力とできる柔軟性を持ち合わせている．これに加え，従来の動画音声においては動画からの予測対象としてメルスペクトログラムが選択されることが多かったが，近年ではこれにテキストや，音声SSLモデルであるHuBERTを利用して得られた離散特徴量を合わせて予測対象とする，マルチタスク学習の有効性が示されている\cite{kim2023lip_multitask,choi2023intelligible}．

% 近年の動画音声合成では，こういったSSLモデルを動画からの特徴抽出器として活用しつつ，さらなる工夫によって精度改善を達成している．動画音声合成について，\cite{kim2023lip_multitask}では予測対象として従来用いられてきたメルスペクトログラムに加え，テキストを予測するマルチタスク学習手法を提案した．損失においては上記の2つに加え，予測したメルスペクトログラムを事前学習済みの音声認識モデルに入力して得られる特徴表現も採用した．音声波形はメルスペクトログラムに対してGriffin-Limアルゴリズムを適用することで獲得しており，従来のメルスペクトログラムのみを損失とする手法に対して客観評価指標における改善を達成した．これに続き，\cite{choi2023intelligible}では前述した手法がテキストアノテーションされたデータのみにしか用いることができないという課題を解消するため，テキストと同様に言語的な情報を持つと考えられている，音声SSLモデルのHuBERT\cite{hsu2021hubert}を利用して得られるHuBERT離散特徴量を用いる手法を提案した．ここで，HuBERT離散特徴量は，HuBERTのTransformer層出力に対してk-means法によるクラスタリングを適用することで得られる．また，予測されたメルスペクトログラムとHuBERT離散特徴量の両方を入力とするMulti-input Vocoderと，Multi-input Vocoderの学習時にメルスペクトログラムにノイズをかけるデータ拡張手法を合わせて提案し，客観評価と主観評価の両方で\cite{kim2023lip_multitask}を含む既存手法に対する改善を達成した．加えて，ここではAVHuBERTの転移学習についても合わせて検討が行われ，これによってさらに性能を改善できることを示した．手法\cite{choi2023intelligible}に関連して，上記のようなマルチタスク学習手法以外にも，HuBERT離散特徴量や，離散化する前の連続特徴量を音声波形までの中間特徴量として扱う手法が存在する．例えば，\cite{hsu2023revise}ではメルスペクトログラムの推定を行わず，HuBERT離散特徴量のみを推定して音声波形に変換する手法が提案された．\cite{choi2023intelligible}では離散化におけるクラスタ数を200としていたのに対して，\cite{hsu2023revise}ではクラスタ数を2000と大きく取っている点で実装が異なっている．メルスペクトログラムを省略する分，クラスタリングによる情報圧縮の程度を軽減することで，音声波形への変換に十分な情報を保持する目的があると考えられる．また，\cite{choi2023intelligible}や\cite{hsu2023revise}ではAVHuBERTを直接動画音声合成にFineTuningしていた一方で，\cite{sahipjohn2023robustl2s}ではAVHuBERTをVSRによってFineTuningし，その後重みを固定した上で特徴抽出器として利用するアプローチを提案している．この手法では，VSRでFineTuningされたAVHuBERTから得られる動画特徴量を入力とし，HuBERT特徴量を予測するネットワークが追加で学習され，HuBERT特徴量のみから音声波形に変換するボコーダを用いることで動画音声合成が実現された．ここで，HuBERT特徴量と表した予測対象について，この研究では他の研究においても検討されたHuBERT離散特徴量だけでなく，クラスタリングによって離散化する前の連続値を用いる場合，離散値と連続値の両方を予測対象とする場合が検討され，連続値のみを予測対象とした場合が最も客観評価指標が優れていたことが示されている．検討された離散値のクラスタ数が100であったことと，\cite{hsu2023revise}の検討とを合わせると，HuBERT離散特徴量のみを用いて音声波形に変換するアプローチを取るのであれば，クラスタ数を十分大きく取る必要があることが示唆される．

% 一方VSRについて，\cite{yeo2024akvsr}では，HuBERT離散特徴量から純粋な言語情報のみを持つCompact Audio Memoryを構築し，これを動画特徴量とアテンションで関連付ける手法を提案した．ここで，Compact Audio MemoryはHuBERT離散特徴量，すなわちインデックス系列を学習可能なベクトルに写し，これを入力とした音声認識モデルを学習させることで得られる．この研究では，HuBERT離散特徴量が言語的な情報のみを持った特徴量であると考えつつ，話者性など言語情報以外の情報が含まれる可能性を考慮して，音声認識に最適化された新たなコードブックを構築することで冗長性を排除した．このCompact Audio Memoryは，VSRモデルの学習時にアテンションをとる対象として用いられる．Compact Audio Memoryが言語情報のみを持つ離散的な表現だと考えると，これは予測対象であるテキストとほとんど同一のものとなるから，提案された手法は予測対象と同等な情報に対するアテンションをモデル内部で取ることによって，最終予測値に対する動画からの特徴抽出をうまく行えるようにネットワークを構成したのだと解釈できる．また，\cite{cheng2023opensr}では，AVHuBERTが動画あるいは音声のどちら一方を入力とした場合でも同じ音素空間にマッピングできる点に着目し，VSRのための学習データを少量に絞ったFew-shot Learningや，VSRのための学習データを用いないZero-shot Learningを検討した．特にZero-shot Learningでは，AVHuBERTの重みを固定したまま音声波形を特徴量に変換して音声認識モデルを学習し，その後動画をAVHuBERTに通して特徴量に変換して音声認識モデルへの入力とすることで，VSR用の学習データを用いることなくテキストの推定が可能であることを示した．加えて，\cite{djilali2023lip2vec}では，AVHuBERTを動画特徴抽出器として利用し，音声認識モデルの中間表現を予測するネットワークを学習するアプローチが提案されている．この手法では，AVHuBERTと音声認識モデルの事前学習済み重みを固定した上で，両者の潜在表現間を繋ぐPrior Networkを学習し，動画から得られる特徴量を音声に近い表現に変換する．この変換された表現を音声認識モデルに入力し，テキストを推定することで，VSRを実現している．
% さらに，静止画像と音声から動画を合成するネットワークを構築し，音声認識用のデータセットを用いてVSRの学習データを大量に合成するデータ拡張手法\cite{liu2023synthvsr}や，事前学習済みの音声認識モデルによって教師なしデータにラベリングを行うデータ拡張手法\cite{ma2023auto}，10万時間分の教師ありデータを新たに増強した研究\cite{chang2024conformer}など，大規模な学習データを確保することで精度改善を達成した例も報告されている．

% 上記の研究は英語データを用いたものであったが，VSRにおいては英語以外の言語に焦点を当てた研究や，多言語対応モデルの構築も検討が進んでいる．\cite{zinonos2023learning}ではRAVEnを利用し，英語に加えてスペイン語，イタリア語，ポルトガル語など計6種類の言語が含まれるデータセット\cite{ephrat2018looking,salesky2021multilingual,zhao2019cascade}を用いて多言語モデルの構築を検討した．結果として，教師ありデータの少ない英語以外の言語に対する，多言語モデルの有効性が明らかとなった．また，\cite{kim2023lip_vsr}では英語データで学習されたAVHuBERTを用いつつ，特定の言語ごとに構築した音声認識モデルのデコーダを転移学習することで，特定言語ごとにモデルを構築するアプローチを提案した．さらに，\cite{yeo2023visual}では音声認識モデルであるWhisperを利用し，教師なしデータへのラベリングによるデータ拡張を行うことで，上記2つのアプローチを超える精度を達成した．

% 本研究では，近年の主流とも言える英語大規模データセットを用いた実験は高い計算スペックを必要とするという課題と，世界的に見て日本語での動画音声合成の検討例が少ないことを考慮して，文献\cite{taguchi,esaki}で収録された日本語データを用いて研究を行うこととした．英語データと比較して小規模なデータである分性能に課題を抱えたが，予備実験として英語データで学習されたAVHuBERTのFineTuningを検討したところ，スクラッチで構築したモデルと比較して，より高い精度を示すことが明らかとなった．しかしながら，それでも依然として合成音声の品質は低く，自然音声に迫る合成音は実現されていないことが課題である．

\subsection{目的}
本研究では，動画音声合成モデルによって得られる合成音声の品質が依然として低く，自然音声に迫る合成音の実現が困難である点を課題とする．この課題に対し，近年高い精度を達成した手法\cite{choi2023intelligible}における，「AVHuBERTを利用したメルスペクトログラムとHuBERT離散特徴量を予測対象とするマルチタスク学習手法」をベースラインとして採用し，この性能を上回る新たなモデルを提案することを目的とする．

% その他にも近年高い精度を達成したモデルは存在\cite{hsu2023revise,sahipjohn2023robustl2s,kim2024let}するが，手法\cite{choi2023intelligible}が採用しているマルチタスク学習の有効性は，テキストを用いた先行研究\cite{kim2023lip_multitask}でも同様に示されている．これより，このアプローチが現状特に有効性が高いと判断し，本研究においてはこの手法をベースラインとして，さらなる改善を狙う形で研究を行うこととした．この手法では，動画を入力としてメルスペクトログラムと音声SSL離散特徴量を推定し，これら両方をMulti-input Vocoderに入力することで音声波形へと変換する．しかし，動画と音声の間には，同様の口の動きであっても声道形状の違いによって生じる発話内容の曖昧さや，話者によるパターンの多様さが存在すると考え，推定を動画のみに依存した先行研究の手法ではこういった側面への対処が難しいと考えた．これに対して本研究では，音声SSLモデルであるHuBERTを利用した動画音声合成モデルを提案し，合成音声の推定残差をHuBERTを利用した後処理によって軽減することで，合成音声の品質改善を狙った．HuBERTは，音声波形を畳み込み層を通すことによってダウンサンプリングしつつ特徴量に変換し，ここでマスクをかけた上でTransformer層を通す．そして，マスクされたフレームにおける予測対象を推定する，Masked Predictionを行うことで学習する．大規模な音声データを用いてこの自己教師あり学習を行うことで，音声のコンテキスト自体をデータそのものから学習することが可能であり，音声認識において有効性が確認されている．本研究では，大規模日本語音声データで事前学習済みのHuBERTを活用し，動画音声合成モデルにおいて生じる推定残差を，音声自体のコンテキストを考慮する形で補うようなアプローチを検討した．

\subsection{本論文の構成}

% \subsection{本論文で用いる演算子}
% \begin{tabular}{|c|l|}
%     \hline
%     記号                              & 説明                         \\
%     \hline
%     $\elemMul$                      & 要素積                        \\
%     \hline
%     $\concat{\cdot, \ldots, \cdot}$ & 特徴量の次元方向の結合                \\
%     \hline
%     $\lrRepeat{\bm{x}}{N}$          & ベクトル$\bm{x}$を$N$回列方向に並べる   \\
%     \hline
%     $\onehot$                       & インデックス系列をOne-hotベクトルに変換    \\
%     \hline
%     $\argmax$                       & 特徴量の次元方向に、最大の値を取るインデックスに変換 \\
%     \hline
% \end{tabular}